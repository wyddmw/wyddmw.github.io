---
title: stereo_matching(3)
date: 2019-08-22
categories: Deep-Learning
tags: 
- depth estimation
- stereo matching
---

接着GC-Net的论文往下进行，这次补充的论文是PSMNet，也算是在GC-Net的基础上进行了一些改进吧。

<!-- more -->

## PSMNet——Pyramid Stereo Matching Network

　　CVPR2018年的一篇论文，主要讲的是如何添加对上下文信息的利用，提出了一种空间池化层和3D卷积的方法。<br>
　　典型的立体匹配pipeline包含基于匹配代价和后处理找到的一致的点。随着卷积神经网络的应用，CNN已经被用来学习如何找到匹配的像素点。早期的应用CNN方法在处理一致性问题的时候将这种问题看做是相似度匹配问题来对待，使用CNN去计算一组图像的相似度分数，然后进一步判断它们是否是匹配的。尽管使用卷积神经网络的方法和传统的方法相比确实在精度和速度方面都取得了不错的提升，在一些病态区域（如重叠区，重复出现的表象、低纹理区域，这些需要全局上下文信息进行整合，SPP和膨胀卷积用来扩大感受野，使得PSM-Net可以将像素级的特征扩展至多尺度区域级的特征。）全局信息和局部信息被用来合成cost volume以得到更可靠的视差估计。

### main contributions

1. 提出了一种端到端的立体匹配学习框架，不需要任何额外的后处理。
2. 介绍了空间金字塔池化模块，用来合并局部和全局的上下文信息。
3. 展示了一种堆栈的漏斗3D卷积网络，来延伸cost volume中语义信息的regional support。

### Network Architecture

　　先给出PSMNet的网络结构

![](/pic/PSMNet_Architecture.png)
![](/pic/PSMNet_Architecture2.png)

　　作者在设计网络结构的时候，首先设计了三层卷积核大小为3的网络，用来提取一些基本的特征。作者在这里用到了空洞卷积的方法，对于空洞卷积，后面对这部分内容再进行补充。添加空洞卷积的目的是为了增大感受野，输出的特征图的分辨率是原始分辨率的1/4大小。接下来添加SPP模块，SPP模块的应用是为了收集上下文的语义信息。我们将左图的特征图和右图的特征图串联起来，得到一个cost volume。最终添加回归项，得到最终的输出视差图。

### Spatial Pyramid Pooling Module

　　包含丰富物体语义信息的图像特征图对于一致性估计的问题来说是有益的（所以如果是添加了丰富的语义信息，对深度估计来说是非常有帮助的，这里的语义分割应该说在计算视差值的时候更有效，计算像素之间的匹配关系），尤其是对于病态区域的点来说。在本篇论文中，一个物体（如一辆车）和其子区域（窗户、轮胎等）之间的关系通过SPP模块获得不同层次的语义信息来学习到。<br>
　　其实感觉这部分的程序和上一篇论文中提出的网络相比，并没有在实质上有很明显的改变，只是添加了一些小小的改动，而且这样的改进很多都是从扩大feature scale的方面来进行的。<br>
　　在论文中，作者谈到，主要的创新点就是引入了空间金字塔池化模块，当前的方法没有利用好上下文信息，于是用SPP聚合多尺度的信息。至于为什么需要添加多尺度的信息，论文中强调的是如果只是施加强度一直的信息是不够的，很多病态区域比如遮挡区域、重复出现的表象低纹理区域、反射表面等，需要全局上下文信息来进行整合。SPP和膨胀卷积用来扩大感受野，使得PSM-Net可以将像素级的特征拓展至多尺度区域级的特征。全局信息和局部信息结合形成cost volume，再用3D卷积的方法融合多通道信息，正则化cost volume，最终预测视差图。其实在之前看语义分割内容的时候，对于一些难分类的像素点来说，需要添加上下文的信息来帮助辅助进行像素点的分类，那篇论文的题目是PSPNet好像，应用的也是金字塔池化，来结合使用多尺度的特征信息。<br>
　　重点看一下立体匹配部分的内容，左右视图在进行特征提取的时候是权重共享的。具体SPP的操作是不同尺度的池化，再上采样串联起来，也就是整合多尺度的信息。看一下cost volume是如何计算的：送到cost volume之前左右图的尺寸是（1,32,96,312），其中32是通道数，96$\times$32是分辨率，cost volume的尺寸是（1,64,48,96,312），64的前32个通道是左视图的，后32个通道是右视图的；48代表视差的维度，也就是说视差的范围是0-47。我们假设当前所在的视差i=10，也就是cost volume的第三个维度是10的时候，第二个维度的前32个通道取x轴上10以后的像素，后32个通道取右图x轴去掉最后10个像素的点，其余的部分都是0。得到cost volume之后，使用3D卷积进一步运算，经过插值还有上采样之后得到（D,H,W）维度，然后用softmax作用于所有视差等级求出各个视差的概率，加权得到最终各像素点的视差，也就是H$\times$W的视差图。
