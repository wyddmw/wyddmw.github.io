---
title: pipeline
date: 2019-10-14
categories: experiment
tags:
- description of our experiment
---

　　这篇文档主要用来记录在组织我们自己的网络模型的过程中，遇到的问题以及想到的解决问题的方法，当我们的这篇文档已经不需要再进行内容添加的时候，我们自己的网络模型就完成了。

<!-- more -->

目前能够想起来的关于实验结果对标的问题

1. 在图像合成方面：gan生成的视图要和deep3D得到的结果进行对标<br>
2. 在深度估计方面的结果 一方面要和使用单目视图进行深度估计的方法比较最终的结果，另一方面也要和使用双目视图进行深度估计的方法做结果的比对。<br>
3. 整理一下gan的程序，在之前的博客上面添加对代码的注释。<br>
4. 条件生成模型中，除了pix2pix中提出的损失函数，还需要额外添加L1范式的约束条件，这样的目的是为了使生成的图像和真实的图像更加接近。除了上面的这个损失函数之外，还可以再额外添加一个用来衡量图像之间相似程度的约束条件。可以尝试借鉴stylegan中的方法，将输入的latent code先转换到另一个空间intermediate latent code，用mlp做一个映射，然后再配合着条件一起输入到判别器中的。噪声的输入可能是导致合成视图中物体外观以及颜色等存在差异的重要原因，这部分可以通过对比实验来进一步说明，目前的思路是不采用噪声作为输入的一环。<br>
5. 一方面需要继续看gan的论文，另一方面需要看一下其他优秀的视图合成的工作。目前找到的两篇相关的论文，一个是LLFF，在image_synthesis的文件夹中<br>

输入图像经过mlp之后得到的特征向量<br>
使用DCGAN可以先来试一试 不添加使用输入的噪声 后面可以考虑添加使用circleGAN<br>
看pix2pix的程序 看stylegan的网络结构 手写<br>

6. 看完了DCGAN，在博客上做一下整理，国庆的时候整理一下建模时用到的相关知识，整理整理博客<br>

7. 定向图像的生成，同样也取决于判别器，然后我们就可以综合来利用circleGAN+pix2pixHD的综合来得到高分辨率的合成图。<br>

***
　　在写程序的时候遇到的问题是如何处理输入图像分辨率 长宽相差较大的问题 需要参看其他的程序来调整分辨率。<br>

8. pix2pix_simple 的输入图像的分辨率的大小调整为了286*286 还是需要看原始的程序来看
需要引入参差网络的网络结构。需要看一下这些初始化方式之间的差别<br>

9. 从目前的实验来看，在不添加噪声的前提下，是可以完成定向的图像生成的，接下来的任务就是如何提高生成图像的质量。两个方向，一个是改善网络的结构，另一个方向是添加一个后处理的步骤，因为将生成一致性的约束添加到了网络结构部分，所以这里的后处理主要强调的内容是图像的去模糊。<br>
10. 关于上面分辨率的问题，发现是自己在想问题的时候想复杂了，因为这部分并不需要降到很低的分辨率之后再进行上采样，是可以将分辨率降低2倍或是降低3倍之后就进行上采样的，这部分是对生成器的网络结构来说的，而对于判别器，也并不需要降采样到1之后计算最后的概率值，算损失值，这对于网络结构的设计可以说是非常大的一个思路解放。

下载了一些用于去模糊的论文，其中也有使用对抗生成网络进行的工作，放在paper的去模糊的文件夹里。

在最终的程序中，使用.yaml来设置网络训练的参数等。 

这个阶段之后 基本上确定下来对抗生成网络的网络结构了。

想要尝试去将DCGAN的网络结构更改为WGAN，为了更够更加稳定地对生成器进行训练，同时不会造成模型多样性的减少。然后在损失函数部分，添加perceptual loss来更好地生成图像的细节。



　　图像的去模糊在之后的学习中可以成为另一个非常重要的研究方向，在现实生活中也有着非常重要的应用，应该说是一个非常基础的视觉领域，在日后如果说找工作的时候也不至于过于受限制。<br>

　　想到一个非常有趣的问题，能不能尝试将2K或是1080的视频源转换到4K或是更高分辨率的视频源呢。这也是非常有趣的一个应用，希望日后有机会也能找机会去做一下尝试。<br>

　　对于我们当前正在研究的深度估计问题，一个非常重要的时间节点是2020年3月份的ECCV，完成初稿。

　　在程序方面，也还需要参考之前的cycle+pix2pix中的网络结构，已经克隆下来，明天看一遍代码。

***

　　画一条分割线，上面的内容记录的有些杂乱，强制一个分割线进行分离。现在分析我们最终得到的实验结果，通过实验结果的分析，发现会有一些生成的图像出现重影，下面给出实验结果中比较理想的一张图像。![](/pic/synthesis.png)

　　可以发现生成的图像是存在一定的重影的，这个重影一定程度上也造成了生成图像的模糊，或者说是位置上的错位，这个问题很大可能会影响到后面双目匹配阶段的精度。对于这个问题，希望能够通过引入语义分割任务的结果来在帮助在边缘上进行限制。使用coupled-gan的整体网络结构。我们尝试去引入WGAN的网络结构，这个网络结构的思路就是将原始GAN在判别器对概率的判断转换为两个分布之间距离的度量，训练判别器的时候，尝试增大了两个分布之间的距离，在训练生成器的过程中，尝试去缩小真实分布和生成分布之间的距离，主要的思路就是这样。

　　后面的Refinement希望能够通过perceptual loss的网络结构来实现。然后网络的编写主要借鉴FlowNetC的结构来实现

***
　　一条很久没有更新的分割线。最近和实验室的朋友一起打一场OCR的比赛，时间紧迫，只能先随手记录一些在比赛过程中认为很重要的点。首先还是要说，自己的代码量和代码能力还是不足，有很多感觉很不错的点子，都没有能够实现，只能在现有程序的基础上不断训练调参数，着就在一定程度上限制了最后的成绩，在后面整理自己的代码的时候，做深度估计实验的时候一定要好好整理自己的程序，函数的参数接口要保留好，写好代码的注释，代码的组织一定要灵活高效，所以说写代码真的不是一个体力活。现阶段还是要继续多看其他人写好的代码。在训练的过程中，一些细节的问题还是更加注意，现在需要注意的方面有：如何命名变量，在训练的过程中，如何合理保存模型——现在感觉不应该只保留最近保留的几个模型，val的作用还是非常重要的，在验证集或是测试集上表现最好的应该保存下来，应该多比较几个模型上的效果再决定最后应该保存哪个模型。除此之外，在训练的过程中要多看看损失函数的变化过程，有必要的话，最好是最后能够把实验过程中的一些数据以表格的形式表现出来，帮助我们对数据进行分析。<br>
　　接下来是训练方面的一些问题，数据确实是非常重要的一个环节，如何有效进行数据的扩充然后帮助我们对模型进行改善，是一个需要好好思考的问题，特别是我面临着数据量不够的现状。在这个比赛中，更进一步认识到数据对于网络模型效果的重要性，网络模型需要通过多次的训练去学习到当前数据集上的特征分布，我负责的其中一个内容就是要伪造和原始数据特征分布相近的数据去训练网络，通过水印平移的方法在800多张数据上得到了和原始特征分布相近的数据， 伪造的数据使得网络在去水印方面的效果有了非常明显的改善，在此之后，使用了finetune的方法，在第一阶段模型的基础上，减小了学习率，再次训练。之前看论文的过程中，一直都没有关注过作者在实验部分的介绍，但是这次比赛过程中，面对着实验的结果，就不知道下一步应该如何对模型的参数进行调整了，所以模型的训练部分也是下一个阶段要重点看的内容，如何先用ImageNet进行训练，然后是如何加载部分的网络进行，对这部分的数据进行微调，直到最后达到令人满意的效果。<br>
　　开始编写整体的网络结构框架程序，第一阶段只完成一个网络模型的编写，不添加额外的判断分支。

***

　　又是一条分割线，在写程序的过程中，发现了一些不太清楚的知识点，记录下来，日后慢慢补课.

- BN中的eps momentum参数的作用

- ~~relu中的inplace的作用是什么~~

***
　　乱七八糟的分割线，目前写完了coupled-gan网络结构的程序，输入右视图，生成预测的左视图和语义分割结果，首先个人感觉，视图合成的效果在可以接受的范围之内，不知道是不是因为添加了语义分割的分支，所以生成的图片中没有很明显的重影的现象，但是目前依然存在着视图模糊的问题有待解决，在接下来的时间中，将perceptual loss添加到视图合成的网络分支中，将语义分割的L1损失去掉，这种强制的添加对语义分割来说感觉是没有意义的。除了添加perceptual loss的网络结构之外，在接下来的时间中要开始完善立体匹配部分的内容，逐渐将整个网络的框架搭起来，先借用gwc的网络结构。
　　除了上面写到的代码方面的问题，还有一些内容是需要完成的，重点看的论文在笔记本的pdf中，需要全部看完，此外，复习SSIM以及PSRN这些衡量图像相似度的指标是如何定义的。网络语义分割部分的内容可能是需要重新考虑一下要如何添加到网络中，可能会放弃掉目前的这个coupled gan的网络结构。
　　在进行图像重建过程中，使用SSIM、PSRN等方式和使用perceptual loss之间的差别，使用SSIM损失函数训练出来的结果在计算SSIM相似程度方面和SSIM损失函数训练出来的网络是存在差别的。
　　必须要开始着手编写第二种网络的结构。

***

　　在做去水印的过程中，发现输入带水印的照片，就能够输出去除水印之后的图片，说明在这个过程中，生成器主要完成了两个工作，一个是找到水印的位置，接着才是将水印去除，所以利用gan的方式说不定能够真正做到anchor-free的水平。在接下来的时间里，完成手边的这个任务，第二个方向做gan和目标检测的融合，想出anchor-free的网络框架。如果这样的框架能够做出来，也许当前整个目标检测的方向都会有新的思路产生。　　