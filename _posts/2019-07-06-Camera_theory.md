---
title: Camera_theory
date: 2019-07-06
categories: Theory
tags: 
- 3D->2D
---

　　既然我们需要从单张图像中恢复出丢失的距离信息，个人觉得，需要先在相机成像的过程中，深度的这一维信息是如何丢掉的，然后反向思维，尝试从单张的图像中去恢复出来丢失的维度。这样的方式，也许能添加更多的几何原理进去，反言之，用神经网络来尝试去寻找图像中存在的几何关系。

<!-- more -->

# 相机成像原理

　　在查看相机成像原理的时候，出现了很多相关的介绍，出现最多的是小孔成像和透视成像这两种成像的方式，但是在看这两种成像原理介绍的时候，没有区分出来这两种成像方式的区别。终于在一篇博客中找到了相关的答案。<br>
　　在不拆掉现代相机的相机镜头时，现代相机运用的是透镜成像原理，在拆掉相机镜头之后，现代相机的机身本身利用的是小孔成像原理。相机的镜头是整个系统的一部分，其作用是获得我们希望的成像效果，但是镜头对于成像来说并不是必要的部件。

![](/pic/camera.bmp)
　　看了多次这个图之后终于算是理解了这个图所表达的原理。经过透镜之后就是


## 小孔成像原理

　　小孔成像的原理中，用到的只是光沿直线传播的原理，并不涉及透镜相关的问题。对于小孔成像的这个实验来说，上述的是其中一个结论，另一个实验的结论是，物距越近，像越大，成像的亮度越暗。因为不涉及透镜，所以也就没有焦距的事了。

## 透镜成像原理

![](/pic/mirror.jpg)

　　此时有了透镜之后，就涉及到焦距的问题了，如果物体在二倍焦距之外，在倒立缩小的实像，二倍焦距处，成倒立等大的实像，二倍焦距和一倍焦距之内，成倒立放大的实像，一倍焦距处不成像，一倍焦距内，放大镜原理，透镜成像的原理就是物距的倒数和像距的倒数之和等于焦距的倒数：

$$
\frac{1}{u}+\frac{1}{v}=\frac{1}{f}
$$

## 几个坐标系

成像模型之间的坐标系的关系是：世界坐标系->相机坐标系->图像坐标系->像素坐标系。

### 世界坐标系
　　客观三维世界的绝对坐标系，也称为客观坐标系。我们使用世界坐标系来描述安放在三维环境中的其他任何物体的位置，坐标的表示为(X<sub>W</sub>,Y<sub>W</sub>,Z<sub>W</sub>)
### 相机坐标系
　　以相机的光心为坐标原点，X轴和Y轴分别平行于图像坐标系的X轴和Y轴，相机的光轴为Z轴，用(X<sub>C</sub>,Y<sub>C</sub>,Z<sub>C</sub>)
### 图像坐标系
　　以CCD图像平面的中心为坐标原点，X轴和Y轴分别平行于图像平面的两条垂直边，用(x,y)表示坐标。图像坐标系是用物理单位(例如毫米)表示像素在图像中的位置。
### 像素坐标系
　　以CCD图像平面的左上角顶点为原点，X轴和Y轴分别平行于图像坐标系的X轴和Y轴，用(u,v)表示其坐标。数码相机采集的图像首先是形成电信号的形式，然后再通过模拟信号转换为数字图像。每幅图像的存储形式为M×N的数组，M行N列的图像中每一个元素的数值代表的是图像点的灰度。每一个元素叫做像素，像素坐标系就是以像素为单位的图像坐标系。
### 齐次坐标
　　其次坐标就是将一个原本n维的向量用一个n+1维的向量来进行表示，是指一个用于投影几何里的坐标系统。

### 深度信息的丢失
　　自己在分析的时候，暂且不考虑相机坐标系和世界坐标系之间的转换。在看分析的过程中，对于使用到的分析模型来说，相机的光圈到物理成像平面之间的距离等于相机的焦距值，利用小孔成像的模型，得到相机坐标系到图像坐标系之间的转换关系：

![](/pic/camera_matrix.jpg)

$$
X\prime=f\frac{X}{Z} \\\
Y\prime=f\frac{Y}{Z}
$$

　　从成像平面映射到像素平面。

$$
u=\alpha{X\prime}+c_x \\\ 
v=\beta{Y\prime}+c_y \\\
$$

　　经过展开之后得到：

$$
u=\alpha{f}\frac{X}{Z}+c_x\\\
v=\beta{f}\frac{Y}{Z}+c_y
$$

　　以向量的形式来表示：

$$
\begin{equation}
\left[
\begin{matrix}
 u\\
 v\\
 1\end{matrix}
\right]\tag{2}=\frac{1}{Z}\times
\left[\begin{matrix}
f_X&0&c_x\\
0&f_y&c_y\\
0&0&1\end{matrix}
\right]\times
\left[
\begin{matrix}
X\\
Y\\
Z\end{matrix}
\right
]
\end{equation}
$$

　　中间的矩阵就是相机的内参矩阵，相机制作好之后这个内参矩阵就基本上确定了。<br>
　　针孔相机模型的成像模型的整个过程是:<br>
  　　1. 首先，世界坐标系下有一个固定的点，世界坐标为P<sub>w</sub><br>
  　　2. 由于相机在运动，它的运动由R，t或是变换矩阵T来进行描述。P的相机坐标为。
  　　3. 此时相机的坐标依然包含三个变量，将它们投影到归一化平面Z=1上，得到P的归一化相机坐标，P<sub>c</sub>=[x/z,y/z,1]<br>
  　　4. 最后，P的归一化坐标经过内参之后，得到对应的像素坐标。

　　深度信息的损失是在投影的过程中丢失的，所以起初设想的通过反向的思维进行深度的恢复这个方法并不能实现。对于相机坐标系而言，X和Y的值都是无法获得的，自然也就不能直接通过简单的推导来获得深度的信息。由此看来，相机成像的投影过程并不是可逆的。
　　
### 双目测距
　　最后还是回到双目测距的原理。<br>
![](/pic/disparity.png)<br>
　　P是空间中的一点，O<sub>r</sub>分别是两个相机的光心，点P在两个物理成像平面上的点是P和P'（正常来说，物理成像的平面应该是在相机镜头的后面，相机的光心到成像平面的距离等于相机的焦距，但是相机的成像平面经过旋转之后放在了相机镜头的前面），重新来理解一下视差的概念。点P和点P'之间的距离称为视差dis。

$$
dis=B-[(X_R-L)+(L-X_T)]=B-(X_R-X_T)\\\
D=X_R-X_T
\frac{(B-(X_R-X_T))}{B}=\frac{Z-f}{Z}\\\
Z=\frac{fB}{X_R-X_T}
$$

　　所以我们在做深度估计任务的时候，最好还是要从图像重建的思路入手，可以利用更多几何约束。