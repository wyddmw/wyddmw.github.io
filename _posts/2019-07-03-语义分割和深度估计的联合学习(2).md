---
title: 语义分割和深度估计的联合学习(2)——RefineNet系列
date: 2019-07-05
categories: Deep-Learning
tags:
- depth estimation
- semantic segmentation
- multi-task learning
---

　　RefineNet可以衍生出一系列的网络模型，最原始的RefineNet网络结构是用来解决语义分割任务的，但是由于其Multi-path的网络结构，经过改进之后的Light-weight RefineNet可以实现实时性的语义分割检测，基于RefineNet的网络结构可以进一步用来实现多任务学习，接下来的两篇联合训练的论文都会基于RefineNet的网络结构来介绍。

<!-- more -->

# RefineNet

　　RefineNet网络结构的提出，目的是为了更合理地利用网络中间层提取出来的特征。作者在摘要中介绍到：我们介绍RefineNet这样一种网络结构，能够明确利用到降采样过程中的全部可用的信息，通过残差连接的方式使得更高分辨率的预测能够实现。除此之外，作者还介绍了链式残差池化——chained residual pooling，这种池化方式能够一种高效的方式捕捉到丰富的背景上下文特征。

　　对于使用卷积神经网络方法来解决语义分割问题而言，使用连续降采样的方式有两大优势：

- 随着卷积的进行，越深的网络层，感受野越大，使得卷积核能够捕捉到更多全局语义信息，这个信息对于高质量的分类而言是非常重要的。
- 运算的开支减小，对存储的要求降低。

　　但是低分辨率的特征图会损失很多由浅层卷积核提取出来的细节，这就会导致一个相对效果很粗糙的分割图。这就是使用卷积神经网络来进行语义分割的限制之一。

　　作者在论文中借助残差网络中的identity mapping的方式来进行，下面会补充一下残差网络的相关知识。

![](/pic/refinenet_arch1.png)

![](/pic/refinenet_arch2.png)

　　RefineNet的网络结构基本如图所示，其实这个网络流图并不能很好地展示出来网络的结构是什么样的，配合着TensorFlow的程序，能够理解地更加清楚：

```python
import tensorflow as tf
improt tensorflow.contrib.slim as slim

def MultiResolutionFusion(high_inputs=None,low_inputs=None,features=256):

    if high_inputs is None:#refineNet block 4
        rcu_low_1 = low_inputs[0]
        rcu_low_2 = low_inputs[1]

        rcu_low_1 = slim.conv2d(rcu_low_1, features, 3)
        rcu_low_2 = slim.conv2d(rcu_low_2, features, 3)

        return tf.add(rcu_low_1,rcu_low_2)

    else:
        rcu_low_1 = low_inputs[0]
        rcu_low_2 = low_inputs[1]

        rcu_low_1 = slim.conv2d(rcu_low_1, features, 3)
        rcu_low_2 = slim.conv2d(rcu_low_2, features, 3)

        rcu_low = tf.add(rcu_low_1,rcu_low_2)

        rcu_high_1 = high_inputs[0]
        rcu_high_2 = high_inputs[1]

        rcu_high_1 = unpool(slim.conv2d(rcu_high_1, features, 3),2)
        rcu_high_2 = unpool(slim.conv2d(rcu_high_2, features, 3),2)

        rcu_high = tf.add(rcu_high_1,rcu_high_2)

        return tf.add(rcu_low, rcu_high)
		#和论文中的multi-resolution的方法相对应，特征传入之后，首先使用3*3的卷积核
		#对于分辨率较小的特征图而言，进行上采样的处理，再将两组特征图进行合并
def RefineBlock(high_inputs=None,low_inputs=None):

    if high_inputs is None: # block 4
        rcu_low_1= ResidualConvUnit(low_inputs, features=256)
        rcu_low_2 = ResidualConvUnit(low_inputs, features=256)
        rcu_low = [rcu_low_1, rcu_low_2]

        fuse = MultiResolutionFusion(high_inputs=None, low_inputs=rcu_low, features=256)
        fuse_pooling = ChainedResidualPooling(fuse, features=256)
        output = ResidualConvUnit(fuse_pooling, features=256)
        return output
    else:
        rcu_low_1 = ResidualConvUnit(low_inputs, features=256)
        rcu_low_2 = ResidualConvUnit(low_inputs, features=256)
        rcu_low = [rcu_low_1, rcu_low_2]

        rcu_high_1 = ResidualConvUnit(high_inputs, features=256)
        rcu_high_2 = ResidualConvUnit(high_inputs, features=256)
        rcu_high = [rcu_high_1, rcu_high_2]

        fuse = MultiResolutionFusion(rcu_high, rcu_low,features=256)
        fuse_pooling = ChainedResidualPooling(fuse, features=256)
        output = ResidualConvUnit(fuse_pooling, features=256)
        return output

def  model():
	#只写一些重要的程序
	logits,end_points=resnet_v1.resnet_v1_101(images)
	f=[end_points['pool5'],end_points['pool4'],
		end_points['pool3'],end_points['pool2']]
	for i in range(4):
		h[i]=slim.conv2d(f[i],256.1)
	g[0]=RefineBlock(high_inputs=None,low_inputs=h[0])
	g[1]=RefineBlock(g[0],h[1])
	g[2]=RefineBlock(g[1],h[2])
	g[3]=RefineBlock(g[2],h[3])
	#输出的都是深度上维度为256的特征图，在muliteresolution中会得到三维的输出特征图
	#经过chainedresidualpooling和一次residualconv之后，输出的都是深度为256的特征图
	#接着和backbone输出的特征图进行合并，较低分辨率的特征图会在multiresolutuionfusion的过程中进行上采样处理。
	F_score=slim.conv2d(g[3],21,1,activation_fn=tf.nn.relu)
	return F_score
	#得到最后各个像素点上的预测结果
```

### Identity mapping 

　　在神经网络中，单纯的一味增加网络的深度会导致梯度爆炸或是弥散的现象，使得网络不能得到有效的训练。如果使用BN和正则化，能够有效改善上述的问题，但是会随之出现退化问题。网络层数增加，但是在训练集上的准确率却饱和甚至下降了。需要注意的是，这个下降是发生在训练集上的，所以这个现象并不能解释为过拟合，因为并不是在测试集上的准确率下降。通过深度残差网络能够解决这个问题，如果深层网络后面的那些层是恒等映射，那么网络模型就退化为一个浅层网络。

　　看到这里，我其实产生了一个疑问，既然是恒等映射，那恒等映射层之后的特征和输入的特征有什么不同呢？既然中间层表示的是恒等映射，那相当于，后面网络层并没有学习到新的特征啊。所以，残差网络只是将网络拓宽了嘛？

![](/pic/identity_mapping.png)

　　做如下的定义：

$$
H(x)=F(x)+X
$$

　　H(x)作为整个网络的输出，X是上一层网络的输出，F(x)就是我们要学习的残差函数，当F(x)=0的时候，整个网络就构成了恒等映射。

![](/pic/ResNet.png)

![](/pic/ResnetArch.png)

# Light-weight RefineNet

　　对RefineNet进行改进，使得网络能够完成实时性的语义分割任务。