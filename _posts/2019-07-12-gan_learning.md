---
title: gan_learning
date: 2019-07-12
categories: Gan-Learning
tags: 
- gan networks
---

　　尝试将对抗生成网络的思想添加到现有的技术中来，但是通过对抗网络来执行什么样的一个任务，现在还没有完全想好。
<!-- more -->

## SGANVO: Unsupervised Deep Visual Odometry and Depth Estimation with Stacked Generative Adversarial Networks

　　这篇论文尝试使用使用gan对抗生成网络来解决深度估计和相机位姿估计的联合问题。也可以看作是一个多任务联合训练的问题吧。建立在下一篇论文的基础上，这篇论文提出使用堆叠对抗网络的方式来训练网络，整个网络的输出任务依然是相机的位姿和输入图像的深度图，网络结构示意图如图所示:

![](/pic/sganvo_arch.png)

　　整个网络结构包含了多个堆叠的gan网络，最低层的网络层用来对深度信息和相机的位姿进行估计，然后上层的网络进行空间特征的估计。因为使用了循环的表现形式，所以可以作者在论文中说到，可以捕获到临时的空间特征。因为使用到了循环卷积神经网络的内容，更具体来说是使用了长短期记忆的形式。不过这部分目前不在我们设计网络结构的框架内，主要是通过这篇论文来看作者是如何实现深度估计的。大致的思路和下文无异，也是通过先估计出深度图然后配合着相机的位姿信息进行图像的重建，最后将重建的图像和原始的图像一同送入到判别器中进行训练。
## GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks

　　这篇论文应该是上一篇论文的基础，在这篇论文的基础上进行了改进之后得到的。先来看一下这篇论文想要做的事情。<br>
　　 作者在这篇论文中想要实现的任务是，提出一个无监督的学习框架，一方面实现对六自由度相机位姿的估计，另一方面从没有经过标注的图像中预测出深度信息来，网络的基本结构示意图如图所示。

![](/pic/ganvo.png)

　　由网络结构的示意图可以看到，整个网络由三个部分组成，位姿的估计、深度估计以及视图重建工作。其中深度估计部分是由对抗生成网络来实现完成，网络的输入是目标帧的RGB图像，生成深度图，再结合预测的六自由度的位姿信息以及相邻帧之间像素的色彩信息来实现图像重建的过程。判别器的功能是尝试去辨别合成的视图和原始真实的视图。生成器的作用是欺骗判别器，生成用于目标图重建的深度图，使得判别器无法区分生成图和原始真是图像。作者在论文中写道，生成器输出的图像被匹配到图像的色彩空间，然后再由判别器来进行真伪的判断，而不是和生成器输出器直接进行比较。

![](/pic/ganvo_2.png)

　　从这个更加更详细的网路结构示意图中可以看出，在图像重建网络之后跟着的就是对抗网络的判别器，判别器将重建的RGB图像尽可能地映射到目标图像。判别器对是否是原始图像进行判断。
　　

## 利用gan结合立体匹配解决深度估计问题
### 出发点
　　我们的出发点是利用单目图像来解决深度估计的问题，为了能够使训练出来的网络取得更好的表现力，我们不采取直接回归的方式进行视差或是深度值的预测，为了能够添加更多的几何约束，最终大思路上决定采用使用立体匹配的方式进行视差的估计。那么单目深度估计的问题就分成了两个问题，一个分支是如何利用单目图像生成双目视图，另一个分支是如何使用双目图像来进行视差的估计。<br>
　　对于立体视图的生成，今天早上看到学习公众号推送的一篇Siamese网络结构的论文，一下子想到为什么不能借用孪生网络的思想来处理呢。但是严格意义上来说，并不是真正利用孪生网络的网络结构，因为孪生网络在输入端是两张图像的输入，之前使用孪生网络时，网络计算出来两个输入图像的特征向量，然后计算两个特征向量的几何距离，对于如何使用这个计算出来的几何距离，根据实际的应用场景再细分。在我们设计的网络结构中，在预测阶段， 一定是单张图像的输入然后进行深度值的估计，所以输入端的双分支结构显然是不行的，然而如果想使用立体匹配的思想的话，就一定要用到双目视觉。怎么办？？？？<br>
　　两个生成器啊！！！！<br>
　　两个生成器，然后对应两个判别器。gan的两个生成器直接去生成左右视图的fake数据，然后判别器对生成的图像进行判别。这个阶段就是利用gan来生成双目的假数据，接下来就是利用双目的假数据去进行深度估计的预测。目前想到的整体网络结构如图：

![](/pic/graph.jpg)

### gan的网络结构

　　在看gan的技术总结的时候，看到了这样的一种gan网络格式，用来学习一组或是说一对图像——CoupledGAN。<br>
　　大部分GAN都是学习单一领域的数据分布，CoupledGAN则是提出了一种部分权重共享的网络网络，使用无监督的方法进行多个域图像的联合分布。<br>

![](/pic/CoupledGAN.png)

　　生成器的前半部分权重共享，目的在于编码两个域高层的共有信息，后半部分没有进行共享，各自编码各自域的数据。判别器前半部分不进行共享，后半部分用于提取高层特征共享共享二者权重。对于训练好的网络，输入一个随机噪声，输出两张不同域的图像。这样的模型学习到的是联合分布，和使用两个独立的gan分别进行训练，学习到的边缘分布是不同的。（虽然我写到这里，也不记得边缘分布是什么概念了）


## 对抗生成网络
　　对抗生成网络，是一种生成式的，对抗网络，生成网络尽可能生成逼真的样本，判别网络尽可能去判别该样本是真实样本还是假的样本数据。

![](/pic/gan_abstract.png)

　　重点理解一下需要优化的目标函数，目标函数如下：

$$
min_G\ max_DV(D,G)\ =\ min_G\ max_D\ E_{x-P{data{(x)}}}[\log{D(x)}]+E_{z-p_z(z)}[\log(1-D(G(z)))]
$$

### objective function
　　对于判别器来说，这是一个二分类的问题，V(D,G)是二分类问题中常见的交叉熵损失函数。对于生成器G来说，为了尽可能欺骗D，需要最大化生成样本的判别概率D(G(Z))，也就是最小化log(1-D(G(Z)))，log(D(X))这一项与生成器是没有关系的。<br>
　　对于这个优化的目标，只是这样理解显然是不够直观的，科学上网查找更多相关的解释，之后会继续补充关于对抗生成网络损失函数的优化方法。

### 损失函数的理解
　　上面的损失函数虽然抄下来了，但是花了很长时间才搞明白minG和maxD到底表示的是什么意思。损失函数都是在判别器部分产生的，判别器的实质是判别真伪，整体上采用的是二分类中的交叉熵损失函数。左边包含两个部分，分别是minG和maxD。看了一些博客的讲解之后，gan的网络结构是由两部分网络组成的。在训练的时候，通常是先保持生成器G不变，训练判别器。判别器的任务是正确区分真伪，判别器的第一个输入采样自真实数据，所以我们期望D(X)趋近于1，也就是期望对于真实的输入，我们希望判别器得到的概率能够尽可能大，越趋近于1，表示越能识别出来真实的图像。此时对于第二项，由于输入的是生成器生成的fake图像，所以我们希望D(G(z)能够趋近于0，而此时对应的第二项由于符号是负，所以相当于也是趋近于1，也是希望能够尽可能大，这就是maxD的含义。<br>
　　在训练的第二阶段，保持判别器不变，对生成器进行训练。这个时候，第一项就不会起到效果了，因为生成器的训练和真实的数据没有关系。因为我们的任务是迷惑判别器，所以我们这个时候将生成的假数据标签为1，也就是让它充当真实的图像，这个时候，我们希望D(G(z))是能够趋近于1的，也就是第二项能够越小越好，这就是minG的含义。<br>
　　所以综上，minG和maxD应该是对应gan训练的两个阶段，在第一阶段训练判别器的时候，我们希望判别器的输出都是能够越大越好，在第二阶段，我们希望判别器的输出能够越小越好。<br>

### 目标函数

重新看了gan的相关内容之后，好像上面说的损失函数并不准确。  