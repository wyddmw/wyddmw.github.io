---

title: 语义分割和深度估计的联合学习(1)
date: 2019-06-29
categories: Deep-Learning
tags:
- depth estimation
- semantic segamentation
- multi-task learning
---

　　这篇论文是南京大学和多伦多大学合作发表的一篇论文，任务是进行深度估计、表面法向量和语义分割的联合任务学习，提出了cross-task propagation和task-specific propagation两种传播方法。

<!-- more -->

## 联合学习存在的问题

　　多任务联合学习其实使用在近些年感觉还是挺热门的一个研究方向的，自己的毕业设计也是抱着尝鲜的心态，选择了做目标检测和深度估计的多任务学习，虽然最后勉强算是实现了功能，实现了一个网络模型能够对目标检测任务和深度估计任务进行预测。

　　自己在选择尝试多任务学习这个题目的时候，出发点是能够借助深度学习的优势，相对较为容易的实现两个任务的融合，有效减少模型参数的数量，提高模型的实时性。在多次毕业设计答辩环节，老师有问一个问题，问什么要选择多任务学习的方式来解决这两个任务，单个任务的效果难道不是比你做这两个任务结合起来的效果更好吗？从最后的实验结果来看，确实在单个任务上的表现要更好一些。之前在看一本书的时候里面写道，多任务学习的方式一方面能够有效扩充数据量，另一方面能够使得不同任务之间可以相互受益，这一点是通过共享底层特征来实现的。最开始做的时候，就是凭借着最初读过的MultiNet这篇论文给出的网络结构，想着将目标检测和深度估计两个任务也设计为这这样一个编码器-解码器结构的网络模型。然而自己的设计过于粗暴，直接将深度估计的编码器部分的网络结构用VGG16来替换，然后强行修改了网络的输入分辨率，借助着fine-tune的思想，冻结其中一个分支之后，训练另一个分支，用着自己标注的数据集和Kitti的双目数据集交替去训练这两个网络的分支。

　　现在来看自己好像确实没有做什么东西，这个感觉就像保送之后重新回顾自己曾经做过的语义分割任务，没有什么自己的原创内容嘛。在做的过程中想着，通过将深度信息引入到目标检测任务中，说不定能够有效提高目标检测任务的识别精度，但是从实验最后的结果来看，这个想法并没有实现，目标检测任务的精度并没有较大程度上的直接提升，深度估计任务有着肉眼可见的效果下降。在进行工作交接的时候，同事问我，我这个工作之后的改进方向或是说问题存在在哪，我想了想，当时想出来了下面三个方面：

1. 首先不应该暴力地直接将深度估计任务的编码器网络结构用VGG16来代替，选择的300*300分辨率现在来看是比较小的，所包含的特征有限。
2. 并没有掌握多任务学习训练的方法，多任务的模型设计的也太草率，多任务模型中底层特征共享的这个优势并没有利用好。现在反思一个很重要的问题：目标检测和深度估计两个任务真的可以设计为多任务模型吗？二者的底层特征真的是可以共享吗？
3. 数据集的问题，用到的两个数据集并不是同一个场景下的数据集，深度估计任务的数据集直接使用了Kitti的双目数据集，目标检测任务使用的是自己标注的数据集，不知道是不是这个原因使得深度估计的特征不能帮助目标检测任务在效果上得到提升。

　　今天看论文的时候，作者对当前的这个多任务学习方法提出的存在问题，个人觉得是非常具有参考价值的：However, most methods aimed to perform fusion or parameter sharing for task interaction. The fusion or sharing ways may utilize the correlative information between tasks,  but there exist some drawbacks. For examples, the integration of different features might result into the ambiguity of information; the fusion does not explicitly model the task-level interaction where we do not know what information are transmitted. 

　　作者说到，对于直接进行特征融合和参数共享的方法而言，作者认为，不同特征的累积可能会导致信息的模糊不清。这样的融合并没有清楚明确地对任务级别的interaction相互影响进行建模，我们并不知道有哪些信息被传递了。相反地，我们能否在多个不同的任务中找到明确的共同模式呢？这就是作者在这篇论文中想要解决的问题，对于自己尝试过多任务的，作者的这个出发点还是非常有价值的。

　　在自己做实验的这个过程中，确实发现了，直接将网络的某些层进行共享之后，训练的过程中，感觉像是揉成了一团，共享底层特征训练到什么样的一种程度并不知道。共享的方法虽然从功能上来说实现了多任务，但是从效果上来说，感觉缺少一些修正或是改善项，所以表现并不理想。

　　对于多任务学习的问题，其实是迁移学习的一种，迁移学习有一个顺序的要求，需要先学习任务A，然后迁移到任务B。在多任务学习中，我们一开始就使用一个神经网络去同时完成多个任务，并且希望这些任务里的每一个任务都能帮助到另一个任务，那么我们应该什么时候来使用呢：

- 在一系列任务上进行训练，它们有共享的低层特征，这使得任务之间相互获益。
- 常见用例：每一个任务的数据量过小。
- 可以训练一个足够大的网络使得它在所有的任务上都能够表现良好。

　　**关键点在于，我们使用的网络必须要足够大，在这个条件下多任务学习才不会对总体性能产生有害影响。**

## Affinity Learning

　　对于这个概念，之前是没有接触过的，然而整个论文似乎又是以这个概念为基础展开的，所以还是需要花时间来整理这个概念。

### Affinity Matrix

　　科学上网搜索这个矩阵的概念，Deepai给出了介绍：

　　**What is an Affinity Matrix?**

　　An Affinity Matrix, also called a Similarity Matrix, is an essential statistical technique used to organize the mutual similarities between a set of data points.  Similarity is similar to distance, however, it does not satisfy the properties of a metric, two points that are the same will have a similarity score of 1, whereas computing the metric will result in zero.  Typical examples of similarity measures are the [cosine similarity](https://deepai.org/machine-learning-glossary-and-terms/cosine-similarity) and the Jaccard similarity.  These similarity measures can be interpreted as the [probability](https://deepai.org/machine-learning-glossary-and-terms/probability) that that two points are related. for example, if two data points have coordinates that are close, then their cosine similarity score ( or respective “affinity” score) will be much closer to 1 than two data points with a lot of space between them.

　　个人感觉翻译为相似度矩阵是合理的，是一个用于计算一组数据点之间共同相似程度的基本统计方法。相似程度和距离这个概念很相似，但是它并不满足一个度量标准应该具备的属性。两个相同的点，它们之间的距离等于0，但是它们的i相似度等于1。两个数据点越接近，它们的相似度越接近1。典型的相似度测量方法有cos similarity和Jaccard similarity，其实想一下在计算两个框的jaccard score的时候，如果两个框重合，jaccard值就等于1。cos similarity计算两个向量夹角的余弦值。
![](/pic/cos.png)

***

　　这篇论文看了两天了，本来都不想看了，不知道作者到底想讲什么内容，晚上的时候静下心来重新梳理了一遍论文的脉络，重新看了一下论文的摘要部分，感觉一下子清楚了很多！

### Abstract

　　In this paper, we propose a novel Pattern-Affinitive Propagation (PAP) framework to jointly predict depth, surface normal and semantic segmentation. The motivation behind it comes from the statistic observation that pattern-affinitive pairs recur much frequently across different tasks as well as within a task. Thus, we can conduct two types of propagations, cross-task propagation and task-specific propagation, to adaptively diffuse those similar patterns. The former integrates cross-task affinity patterns to adapt to each task therein through the calculation on non-local relationships. Next the latter performs an iterative diffusion in the feature space so that the cross-task affinity patterns can be widelyspread within the task. Accordingly, the learning of each task can be regularized and boosted by the complementary
task-level affinities. Extensive experiments demonstrate the effectiveness and the superiority of our method on the joint three tasks. Meanwhile, we achieve the state-of-the-art or competitive results on the three related datasets, NYUD-v2, SUN-RGBD and KITTI.

　　作者在论文的摘要中写道：我们提出了两种传播的方式，前者累积cross-task affinity patterns（应该是翻译为交叉任务的相似度模式，在计算非局部关系的过程中调整适应每一个任务。后一个传播方式在特征空间循环扩散这些相似度的，所以cross-task affinity patterns能够在每一个任务内分离出来。因此，对于每一个任务的学习能够通过这些任务级的大量信息中被正规化（正则化）和加速。

　　所以，作者在这篇论文中并没有提出新的网络结构，在论文的图中确实也看到了，各个任务模块作者直接写了sub-net来代替，作者在这篇论文中的创新点在于去学习在不同任务中的相似度模式进而起到模型改善的效果。

　　我们可以计算每个像素点和其他各个像素点之间的相似度关系，经过统计可以知道，对于不同的任务而言，有一些相似点对和不相似点对在同一个位置上是相同的，这就是整篇论文的出发点，作者想要利用的就是这些相似度模式信息来改善多任务的效果，将这些相似度关系进一步传递到特征空间中。

![](/pic/PAP_pipeline.png)

 　　整个网络的pipeline如图所示，一直到sub-net部分，都和正常的编码器-解码器的网络模型没有差别，共享参数。接下来输出一个较低分辨率的估计结果，通过一个affinity-learning layer计算出来每一个任务各自的pair-wise的相似度矩阵，然后将这相似度矩阵和其他两个任务的相似度矩阵相结合，来累积和任务相关的信息。接下来，通过一个传播层diffusion layer来执行特定任务的传播将学习到的相似度信息传递到特征空间中，经过扩散(diffuesd，不知道应该如何翻译这个单词最为合适)之后的特征被进一步送入到一个重建网络中，来生成更高分辨率的最终预测结果。

![](/pic/affinity_learning.png)
 　　在cross-task propagation中，经过affinity learning layer得到affinity matrix **M**，**M**能够用来表示任务级别的模式。The task-level patterns can be represented in each M.接下来，我们想要给每一个任务都累积跨任务的信息：We want to integrate the cross-task information for each task.将多个任务的相似度矩阵进行融合的方式是将不同任务对应的相似度矩阵进行加权操作，得到最后的cross-task相似度模式的相似度矩阵：

$$
\hat{M}_{T_i}=\alpha_1^{T_i}\cdot{M_{T_1}}+\alpha_2^{T_i}\cdot{M_{T_2}}+\alpha_3^{T_i}\cdot{M_{T_3}}
$$

 　　对于每一个任务而言，对应的**M**都是不一样的。

 　　在task-specific propagation的处理中，每个位置对应的特征向量通过使用学习到的相似度特征进而得到加权特征向量来获得（这个翻译实在是拗口）——In this way, the feature vectore of each position is obtained by weighted  accumulating feature vectors of all positions using the learned affinity.由于是使用循环扩散的方式，所以扩散的特征向量表示为：

$$
h^{t+1}=\hat{M}h^t,t\geq0　　
$$

 　　其中h<sup>t</sup>表示的是在第t步得到的特征，经过t次循环扩散之后得到的特征输出等于：　

$$
h^{out}=\beta{h}^{t^*}+(1-\beta)h^0,0\leq\beta\geq1
$$



　　通过这种方式，学习到的每个任务的相似度特征矩阵就能够传递到每一个对应的任务中去了。

### 损失函数

　　整个网络的损失函数的表达式如下，表达形式也是多个损失函数的加权和。

$$
L=\sum_{T_i}\lambda_{Ti}({L^{T_i}+\xi_{T_i}L^{T_i}_{pair-wise}})
$$

$$
L_{pair-wise}=\sum_{S}|{\hat{d}_{ij}}-d_{ij}|
$$

$$
\hat{d}_{ij}=|{\hat{z}_i}-{\hat{z}_j}|
$$

$$
d_{ij}=|{z_i}-{z_j}|
$$

　　其中S表示的是对于每一个任务而言随机选择S对然后来计算pair-wise loss.