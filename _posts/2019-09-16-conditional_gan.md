---
title: conditional_gan
date: 2019-09-16
categories: Gan-Learning
tags:
- 条件对抗生成模型
- pix2pix
---

　　之前看的gan模型中，所有的输入都是随机向量，但是这样的网络结构导致最终生成的结果是随机的，也就是我们无法控制生成的结果朝着我们希望的方向进行。但是在我们自己的网络模型任务中，我们需要通过给定的输入左视图，定向地生成对应的右视图，如果不添加条件的约束，显然是无法实现这样的效果的。所以补充条件生成网络模型的内容。<br>
　　因为我们最终的目标是通过左视图来生成右视图，基本的网络结构框架目前选择参考pix2pix的网络结构。

<!-- more -->

## conditional generative adversarial Nets
　　传统的生成对抗网络如果在生成器和判别器部分添加一些额外的条件信息y，那么对抗生成网络能够扩展为条件生成网络。y可以是任何辅助的信息，比如是类别的标签或是其他模态的信息。我们可以将y作为额外层添加到生成器和判别器中来引入条件约束。在生成器部分，输入的随机向量p(z)和额外的条件信息y进行了合并，得到一个联合隐式表达。在判别器部分x和y作为输入，之后送入到一个判别函数中，x和y通过MLP多层感知器进行合并。直接给出抽象的模型结构：![](/pic/cgan.png)
<<<<<<< HEAD
　　在生成器中，输入的噪声和作为条件信息的y会被合并为一个隐式表示hidden representation，对抗网络的训练框架对于这个隐式表达hidden representation是如何组成的有很大的灵活性。<br>
　　在作者给出的示例中，使用的是mnist数据集来完成这个任务，对应的条件信息是经过编码之后的one-hot格式的标签信息。
=======
　　
## pix2pix
　　pix2pix的这篇论文
>>>>>>> f50343c6005f0e72fa623feaea907f7e49ab5412
