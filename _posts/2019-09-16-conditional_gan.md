---
title: conditional_gan
date: 2019-09-16
categories: Gan-Learning
tags:
- 条件对抗生成模型
- pix2pix
---

　　之前看的gan模型中，所有的输入都是随机向量，但是这样的网络结构导致最终生成的结果是随机的，也就是我们无法控制生成的结果朝着我们希望的方向进行。但是在我们自己的网络模型任务中，我们需要通过给定的输入左视图，定向地生成对应的右视图，如果不添加条件的约束，显然是无法实现这样的效果的。所以补充条件生成网络模型的内容。<br>
　　因为我们最终的目标是通过左视图来生成右视图，基本的网络结构框架目前选择参考pix2pix的网络结构。

<!-- more -->

## conditional generative adversarial Nets
　　传统的生成对抗网络如果在生成器和判别器部分添加一些额外的条件信息y，那么对抗生成网络能够扩展为条件生成网络。y可以是任何辅助的信息，比如是类别的标签或是其他模态的信息。我们可以将y作为额外层添加到生成器和判别器中来引入条件约束。在生成器部分，输入的随机向量p(z)和额外的条件信息y进行了合并，得到一个联合隐式表达。在判别器部分x和y作为输入，之后送入到一个判别函数中，x和y通过MLP多层感知器进行合并。直接给出抽象的模型结构：![](/pic/cgan.png)
<<<<<<< HEAD
　　在生成器中，输入的噪声和作为条件信息的y会被合并为一个隐式表示hidden representation，对抗网络的训练框架对于这个隐式表达hidden representation是如何组成的有很大的灵活性。<br>
　　在作者给出的示例中，使用的是mnist数据集来完成这个任务，对应的条件信息是经过编码之后的one-hot格式的标签信息。
=======
　　
## pix2pix
　　pix2pix的这篇论文，目的是为了构建一个具有普适性的框架来完成不同任务间的从像素点到像素点的合成，主要使用的方法还是基于条件生成模型。为什么不直接使用cnn，然后给出一个简单的约束直接来进行图像的合成任务呢，作者在论文中指出，如果我们只是采用简单的方法然后使CNN去最小化合成得到的图像和真实图像之间的欧式距离的化，这样得到的合成视图使非常模糊的，这是因为欧式距离最小化的全部的可能的输出像素值，这就导致了最终生成图像的模糊。从基本的条件生成模型来看，生成模型的输入由两部分组成，一方面是随机的噪声，另一方面是代表条件的信息。<br>
　　在之前的一些工作中已经发现了，如果将gan的目标检测和一些更传统的损失函数如L2距离损失函数，这样做可以使得gan的效果更理想。判别器的任务并没有发生改变，依然是判断输入到判别器中的数据是来自真实数据还是生成的假的数据。所以在作者给出的论文中，最终使用的目标函数:
$$
G=argmin_Gmax_DL_{cGan}(G,D)+\Lambda{L_{L1}(G)}
$$
